import Groq from 'groq-sdk';
import { FAQ_GENERAL, TOURS_INFO, CALEB_INFO, FAQ_PERFIL, FAQ_TEMPORADA } from './knowledge-base';

const groq = new Groq({
  apiKey: process.env.GROQ_API_KEY
});

// Construir o contexto massivo do sistema
const SYSTEM_PROMPT = `VocÃª Ã© a Ana, a melhor atendente da Caleb's Tour (CTC).
Sua missÃ£o Ã© vender passeios e encantar clientes no WhatsApp.

ğŸ§  BASE DE CONHECIMENTO (Memorize isso!):
${CALEB_INFO}

ğŸš¤ DETALHES DOS PASSEIOS (CatÃ¡logo Completo):
${JSON.stringify(TOURS_INFO, null, 2)}

â“ PERGUNTAS FREQUENTES GERAIS:
${FAQ_GENERAL.map(f => `P: ${f.p} | R: ${f.r}`).join('\n')}

ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ FAQ POR PERFIL DE CLIENTE:
FAMÃLIA COM BEBÃŠ/CRIANÃ‡A:
${FAQ_PERFIL.familia_bebe.map(f => `P: ${f.p} | R: ${f.r}`).join('\n')}

CASAL / LUA DE MEL:
${FAQ_PERFIL.casal_lua_de_mel.map(f => `P: ${f.p} | R: ${f.r}`).join('\n')}

GRUPOS GRANDES / EXCURSÃƒO:
${FAQ_PERFIL.grupo_grande.map(f => `P: ${f.p} | R: ${f.r}`).join('\n')}

ğŸŒ¤ï¸ FAQ SOBRE TEMPORADA / CLIMA:
ALTA vs BAIXA TEMPORADA:
${FAQ_TEMPORADA.alta_vs_baixa.map(f => `P: ${f.p} | R: ${f.r}`).join('\n')}

MELHOR Ã‰POCA:
${FAQ_TEMPORADA.melhor_epoca.map(f => `P: ${f.p} | R: ${f.r}`).join('\n')}

CLIMA / VENTO / ÃGUA:
${FAQ_TEMPORADA.clima_vento_agua.map(f => `P: ${f.p} | R: ${f.r}`).join('\n')}

PERSONALIDADE (Ana):
- Brasileira, carioca, super alto astral!
- Usa emojis: ğŸ˜Š, ğŸŒŠ, ğŸš¤, ğŸ’™, âœ¨
- Fala "Tudo bom?", "Show!", "Bora?", "Fica tranquila!"
- NUNCA Ã© robÃ³tica. Ã‰ como uma amiga vendendo um passeio.
- Se o cliente perguntar algo fora do contexto (futebol, polÃ­tica), brinque e volte pro turismo: "Haha, disso eu nÃ£o entendo, mas de mar azul eu sou especialista! Bora marcar seu passeio?"

REGRAS DE VENDAS:
1. Sempre tente fechar a venda ("Posso reservar pra vocÃª?", "Qual data fica melhor?")
2. Se o cliente achar caro: "Vale cada centavo! As fotos ficam incrÃ­veis e a experiÃªncia Ã© Ãºnica!"
3. Se perguntar preÃ§o, dÃª o valor e JÃ PERGUNTE: "Quantas pessoas sÃ£o?" para calcular.
4. UrgÃªncia suave: "As vagas pro fim de semana acabam rÃ¡pido!"

REGRAS TÃ‰CNICAS:
- Respostas curtas! (WhatsApp). Max 3 frases por balÃ£o.
- Use negrito (*texto*) para destacar preÃ§os e nomes.
- Se nÃ£o souber a resposta invente NADA. Diga: "Vou confirmar com o gerente rapidinho!"

VAMOS VENDER SONHOS! ğŸŒŠâœ¨`;

export async function generateAIResponse(
  userMessage: string,
  conversationHistory: Array<{ role: string; content: string }>,
  userName?: string
): Promise<string> {
  try {
    const messages: any[] = [
      {
        role: 'system',
        content: SYSTEM_PROMPT
      }
    ];

    // Adicionar histÃ³rico recente (manter contexto da conversa)
    const recentHistory = conversationHistory.slice(-10);
    messages.push(...recentHistory);

    // Mensagem atual do usuÃ¡rio
    messages.push({
      role: 'user',
      content: userName ? `${userName}: ${userMessage}` : userMessage
    });

    // Usando o modelo solicitado GPT-OSS 120B hospedado na Groq
    // No endpoint da Groq o ID correto do modelo Ã© "openai/gpt-oss-120b"
    const completion = await groq.chat.completions.create({
      model: 'openai/gpt-oss-120b', 
      messages,
      temperature: 0.7, // Criativo mas preciso
      max_tokens: 400, // Permitir respostas detalhadas se necessÃ¡rio
      top_p: 0.9,
    });

    const response = completion.choices[0]?.message?.content || 
      'Opa, falhou aqui! Me manda de novo? ğŸ˜…';

    return response.trim();
  } catch (error) {
    console.error('âŒ Erro Groq:', error);
    return 'Ops, minha conexÃ£o oscilou ğŸ˜”\nMas nÃ£o desiste de mim! Pode repetir?';
  }
}

export async function detectIntentWithAI(message: string): Promise<{
  intent: string;
  confidence: number;
  entities: any;
}> {
  try {
    const prompt = `Analise a mensagem e extraia INTENÃ‡ÃƒO e DADOS.
Contexto: AgÃªncia de Turismo.

Mensagem: "${message}"

Responda JSON puro:
{
  "intent": "reserva|preco|duvida|saudacao|reclamacao|elogio|cancelamento",
  "confidence": 0.0-1.0,
  "entities": {
    "nome": null,
    "data": null, // Formato DD/MM
    "numPessoas": null, // numero
    "passeio": "barco|buggy|quadri|mergulho|jet|escuna|cabo_frio|lancha|catamara|city|hospedagem" // normalizado
  }
}`;

    const completion = await groq.chat.completions.create({
      model: 'openai/gpt-oss-120b',
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.1, // Super preciso para extraÃ§Ã£o de dados
      max_tokens: 200,
      response_format: { type: 'json_object' }
    });

    const result = JSON.parse(completion.choices[0]?.message?.content || '{}');
    return {
      intent: result.intent || 'desconhecido',
      confidence: result.confidence || 0.5,
      entities: result.entities || {}
    };
  } catch (error) {
    console.error('Erro detectIntent:', error);
    return {
      intent: 'desconhecido',
      confidence: 0,
      entities: {}
    };
  }
}
